{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "icevision_app.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ai-fast-track/icevision-gradio/blob/master/icevision_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXYneBY9HKCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install git+git://github.com/airctic/mantisshrimp.git#egg=mantisshrimp[inference] --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGaD1jw0H9Tj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install gradio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PDsjGDbHBZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mantisshrimp.all import *\n",
        "import PIL, requests\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import gradio as gr"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AstBZCMHBZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MASK_PENNFUNDAN_WEIGHTS_URL = \"https://mantisshrimp-models.s3.us-east-2.amazonaws.com/pennfundan_maskrcnn_resnet50fpn.zip\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i0d7lnGHBZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(class_map=class_map, url=None):\n",
        "    if url is None:\n",
        "        # print(\"Please provide a valid URL\")\n",
        "        return None\n",
        "    else:\n",
        "        model = mask_rcnn.model(num_classes=len(class_map))\n",
        "        state_dict = torch.hub.load_state_dict_from_url(\n",
        "            url, map_location=torch.device(\"cpu\")\n",
        "        )\n",
        "        model.load_state_dict(state_dict)\n",
        "        return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uPev7wiHBZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_map = datasets.pennfundan.class_map()\n",
        "model = load_model(class_map=class_map, url=MASK_PENNFUNDAN_WEIGHTS_URL)\n",
        "# print(\"class_map: \", class_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIzikSZLHBZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(\n",
        "    model, image, detection_threshold: float = 0.5, mask_threshold: float = 0.5\n",
        "):\n",
        "    # img = np.array(image)\n",
        "    tfms_ = tfms.A.Adapter([tfms.A.Normalize()])\n",
        "    # Whenever you have images in memory (numpy arrays) you can use `Dataset.from_images`\n",
        "    infer_ds = Dataset.from_images([image], tfms_)\n",
        "\n",
        "    batch, samples = mask_rcnn.build_infer_batch(infer_ds)\n",
        "    preds = mask_rcnn.predict(\n",
        "        model=model,\n",
        "        batch=batch,\n",
        "        detection_threshold=detection_threshold,\n",
        "        mask_threshold=mask_threshold,\n",
        "    )\n",
        "    return samples[0][\"img\"], preds[0]\n",
        "\n",
        "def get_masks(input_image, display_list, detection_threshold, mask_threshold):\n",
        "    display_label = (\"Label\" in display_list)\n",
        "    display_bbox = (\"BBox\" in display_list)\n",
        "    display_mask = (\"Mask\" in display_list)\n",
        "\n",
        "    if detection_threshold==0: detection_threshold=0.5\n",
        "    if mask_threshold==0: mask_threshold=0.5\n",
        "    \n",
        "    img, pred = predict(model=model, image=input_image, detection_threshold=detection_threshold, mask_threshold=mask_threshold)\n",
        "    # print(pred)\n",
        "    img = draw_pred(img=img, pred=pred, class_map=class_map, denormalize_fn=denormalize_imagenet, display_label=display_label, display_bbox=display_bbox, display_mask=display_mask)\n",
        "    img = PIL.Image.fromarray(img)\n",
        "    print(\"Output Image: \", img.size, type(img))\n",
        "    return img"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tGwcfYUHBZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = gr.outputs.Image(type=\"pil\")\n",
        "display_chkbox = gr.inputs.CheckboxGroup([\"Label\", \"BBox\", \"Mask\"], label=\"Display\")\n",
        "detection_threshold_slider = gr.inputs.Slider(minimum=0, maximum=1, step=0.1, default=0.5, label=\"Detection Threshold\")\n",
        "\n",
        "mask_threshold_slider = gr.inputs.Slider(minimum=0, maximum=1, step=0.1, default=0.5, label=\"Mask Threshold\")\n",
        "\n",
        "gr_interface = gr.Interface(fn=get_masks, inputs=[\"image\", display_chkbox, detection_threshold_slider, mask_threshold_slider], outputs=outputs, title='IceVision - Ice Simple')\n",
        "gr_interface.launch(inline=False, share=True, debug=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}